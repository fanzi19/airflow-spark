name: K8s Data Pipeline CI/CD

on:
  push:
    branches: [ main ]
    paths:
      - 'dags/**'
      - 'docker/**'
      - 'k8s/**'
      - 'spark/**'
      - 'hadoop/**'
  workflow_dispatch:

env:
  REGISTRY: docker.io
  IMAGE_NAME: ${{ secrets.REGISTRY_USERNAME }}/airflow-spark
  IMAGE_TAG: ${{ github.sha }}
  K8S_NAMESPACE: data-platform

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Install yamllint
      run: |
        sudo apt-get install yamllint

    - name: Validate YAML syntax
      run: |
        echo "Checking YAML files in k8s directory..."
        for file in k8s/**/*.yaml; do
          if [ -f "$file" ]; then
            echo "Validating $file"
            yamllint -d relaxed "$file" || echo "Warning: Issues found in $file"
          fi
        done

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install test dependencies
      run: |
        pip install pytest pytest-cov apache-airflow

    - name: Login to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.REGISTRY_USERNAME }}
        password: ${{ secrets.REGISTRY_PASSWORD }}

    - name: Validate DAGs
      if: hashFiles('dags/tests/**/*.py') != ''
      run: |
        python -m pytest dags/tests/ -v
